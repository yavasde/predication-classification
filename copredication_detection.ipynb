{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copredication Detection with Argument Semantic Type Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our classifiers that are trained for the identification of argument semantic types in predications to detect copredication. First, we parse the sentences to identify verb-direct object and adjective-noun pairs in the sentences. We classify each predication with the relative classifiers. We select the sentences in which the predications are classified as positive by different semantic type classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yavas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\util.py:732: UserWarning: [W095] Model 'en_core_web_trf' (3.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "type_one = \"Artifact\"\n",
    "type_two = \"Event\"\n",
    "\n",
    "with open(f\"classifiers/{type_one}_verb_clf.pickle\", \"rb\") as classifier_file:\n",
    "    clf1_verb = pickle.load(classifier_file)\n",
    "with open(f\"classifiers/{type_one}_adj_clf.pickle\", \"rb\") as classifier_file:\n",
    "    clf1_adj = pickle.load(classifier_file)\n",
    "with open(f\"classifiers/{type_two}_verb_clf.pickle\", \"rb\") as classifier_file:\n",
    "    clf2_verb = pickle.load(classifier_file)\n",
    "with open(f\"classifiers/{type_two}_adj_clf.pickle\", \"rb\") as classifier_file:\n",
    "    clf2_adj = pickle.load(classifier_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_vector(tokenizer, model, sentence, items):\n",
    "    item1_vector = get_averaged_vector(tokenizer, model, sentence, items[0])\n",
    "    item2_vector = get_averaged_vector(tokenizer, model, sentence, items[1])\n",
    "    if item1_vector is not None and item2_vector is not None:\n",
    "        return np.concatenate((item1_vector, item2_vector), axis=1)\n",
    "\n",
    "\n",
    "def get_averaged_vector(tokenizer, model, sentence, word):\n",
    "    inputs = tokenizer(sentence, truncation=True, return_tensors=\"pt\")\n",
    "    word_char = sentence.index(word)\n",
    "    token_id = inputs.char_to_token(word_char)\n",
    "    output = model(**inputs, output_hidden_states=True).hidden_states\n",
    "    vectors = [\n",
    "        output[layer_no][:, token_id, :].detach().numpy() for layer_no in range(8, 12)\n",
    "    ]\n",
    "    return np.average(vectors, axis=0)\n",
    "\n",
    "\n",
    "def get_verbobj(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"dobj\":\n",
    "                    return (token.text, child.text)\n",
    "\n",
    "\n",
    "def get_adjnoun(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"amod\":\n",
    "                    return (token.text, child.text)\n",
    "\n",
    "\n",
    "def get_predications(rvector_verb, rvector_adj):\n",
    "    verb_pred1 = clf1_verb.predict(np.asarray(rvector_verb, \"float64\").reshape(1, -1))\n",
    "    adj_pred1 = clf1_adj.predict(np.asarray(rvector_adj, \"float64\").reshape(1, -1))\n",
    "    verb_pred2 = clf2_verb.predict(np.asarray(rvector_verb, \"float64\").reshape(1, -1))\n",
    "    adj_pred2 = clf2_adj.predict(np.asarray(rvector_adj, \"float64\").reshape(1, -1))\n",
    "    return verb_pred1, adj_pred1, verb_pred2, adj_pred2\n",
    "\n",
    "\n",
    "def detect_copredication(sentence):\n",
    "    items_verb = get_verbobj(sentence)\n",
    "    items_adj = get_adjnoun(sentence)\n",
    "    rvector_verb = get_relation_vector(tokenizer, model, sentence, items_verb)\n",
    "    rvector_adj = get_relation_vector(tokenizer, model, sentence, items_adj)\n",
    "\n",
    "    if rvector_adj is not None and rvector_verb is not None:\n",
    "        verb_pred1, adj_pred1, verb_pred2, adj_pred2 = get_predications(\n",
    "            rvector_verb, rvector_adj\n",
    "        )\n",
    "        if verb_pred1 == [1] and adj_pred2 == [1]:\n",
    "            print(f\"Copredication Detected. Type: {type_one}-{type_two}\")\n",
    "        elif verb_pred2 == [1] and adj_pred1 == [1]:\n",
    "            print(f\"Copredication Detected. Type: {type_two}-{type_one}\")\n",
    "        elif verb_pred1 == [1] and adj_pred1 == [1]:\n",
    "            print(f\"Copredication NOT Detected.\" f\" Type: {type_one}-{type_one}\")\n",
    "        elif verb_pred2 == [1] and adj_pred2 == [1]:\n",
    "            print(f\"Copredication NOT Detected.\" f\" Type: {type_two}-{type_two}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copredication Detected. Type: Event-Artifact\n"
     ]
    }
   ],
   "source": [
    "sentence = \"She attended a delicious breakfast.\"\n",
    "detect_copredication(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copredication Detected. Type: Artifact-Event\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I cooked a romantic lunch.\"\n",
    "detect_copredication(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copredication NOT Detected. Type: Artifact-Artifact\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I ate a delicious breakfast.\"\n",
    "detect_copredication(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copredication NOT Detected. Type: Artifact-Artifact\n"
     ]
    }
   ],
   "source": [
    "sentence = \"She ate a hot soup.\"\n",
    "detect_copredication(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copredication NOT Detected. Type: Event-Event\n"
     ]
    }
   ],
   "source": [
    "sentence = \"We organized a formal event.\"\n",
    "detect_copredication(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copredication NOT Detected. Type: Event-Event\n"
     ]
    }
   ],
   "source": [
    "sentence = \"We attended a formal dinner.\"\n",
    "detect_copredication(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
